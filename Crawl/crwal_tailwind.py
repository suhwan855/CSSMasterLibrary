import psycopg2, time, re, concurrent.futures, threading, os, math
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager

# --- DB ì—°ê²° ---
conn = psycopg2.connect(
    host="220.74.18.216",
    dbname="daelim",
    user="admin",
    password="qwe123",
    port="5432"
)
cur = conn.cursor()
lock = threading.Lock()

# --- í¬ë¡¬ ì˜µì…˜ ---
def get_driver():
    options = Options()
    options.add_argument("--headless")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    return webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)

BASE_URL = "https://www.creative-tim.com/twcomponents/components"
PROGRESS_FILE = "progress.txt"
ERROR_LOG = "error_log.txt"
OUTPUT_LOG = "output_log.txt"

# --- ìœ í‹¸ ---
def log_error(msg):
    with open(ERROR_LOG, "a", encoding="utf-8") as f:
        f.write(f"{time.strftime('%Y-%m-%d %H:%M:%S')} - {msg}\n")

def log_output(msg):
    with open(OUTPUT_LOG, "a", encoding="utf-8") as f:
        f.write(f"{time.strftime('%Y-%m-%d %H:%M:%S')} - {msg}\n")

def is_duplicate(link):
    with lock:
        cur.execute("SELECT 1 FROM components_tbl_test WHERE components_source_url = %s LIMIT 1;", (link,))
        return cur.fetchone() is not None

# --- ì¹´í…Œê³ ë¦¬ ìˆ˜ì§‘ ---
def get_categories():
    driver = get_driver()
    driver.get(BASE_URL)

    # ì¹´í…Œê³ ë¦¬ ë¡œë“œë  ë•Œê¹Œì§€ ëŒ€ê¸°
    try:
        WebDriverWait(driver, 15).until(
            EC.presence_of_all_elements_located((
                By.CSS_SELECTOR,
                "a.px-3.py-1\\.5.text-gray-500.dark\\:text-gray-400.rounded-lg.capitalize.hover\\:bg-gray-100.dark\\:hover\\:bg-gray-800"
            ))
        )
    except Exception as e:
        print("âš ï¸ ì¹´í…Œê³ ë¦¬ ë¡œë“œ ì‹¤íŒ¨:", e)
        driver.quit()
        return []

    # ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ
    cat_elems = driver.find_elements(
        By.CSS_SELECTOR,
        "a.px-3.py-1\\.5.text-gray-500.dark\\:text-gray-400.rounded-lg.capitalize.hover\\:bg-gray-100.dark\\:hover\\:bg-gray-800"
    )

    categories = []
    for elem in cat_elems:
        name = elem.text.strip()
        href = elem.get_attribute("href")

        # Allë§Œ ì œì™¸
        if name.lower() == "all":
            continue

        if href and name:
            categories.append((name, href))

    print(f"ğŸ“š ì´ {len(categories)}ê°œ ì¹´í…Œê³ ë¦¬ ë°œê²¬!")
    for i, (n, h) in enumerate(categories, 1):
        print(f"   {i}. {n} â†’ {h}")

    driver.quit()
    return categories


# --- í˜ì´ì§€ ë‹¨ìœ„ ë§í¬ ìˆ˜ì§‘ ---
def crawl_page(url):
    try:
        driver = get_driver()
        driver.get(url)
        WebDriverWait(driver, 10).until(
            EC.presence_of_all_elements_located((By.CSS_SELECTOR, "a[href*='/component/']"))
        )
        cards = driver.find_elements(By.CSS_SELECTOR, "a[href*='/component/']")
        links = list({c.get_attribute("href") for c in cards if c.get_attribute("href")})
        driver.quit()
        return links
    except Exception as e:
        log_error(f"í˜ì´ì§€ ë¡œë“œ ì‹¤íŒ¨: {url} - {e}")
        return []

# --- ìƒì„¸ í˜ì´ì§€ í¬ë¡¤ë§ ---
def crawl_detail(link, category):
    start = time.time()
    try:
        if is_duplicate(link):
            msg = f"â© ì¤‘ë³µ ìŠ¤í‚µ: {link}"
            log_output(msg)
            return msg

        driver = get_driver()
        driver.get(link)

        # ì´ë¦„
        try:
            name_elem = WebDriverWait(driver, 10).until(
                EC.presence_of_element_located(
                    (By.CSS_SELECTOR, "h1.text-2xl.font-semibold.text-gray-800.dark\\:text-gray-200")
                )
            )
            name = name_elem.text.strip()
        except:
            name = link.split("/")[-1]

        # ì„¤ëª…
        try:
            desc_elem = driver.find_element(
                By.CSS_SELECTOR,
                "p.mt-2.text-gray-500.dark\\:text-gray-400.lg\\:max-w-xl.description-link"
            )
            description = desc_elem.text.strip()
        except:
            description = None

        # ì‘ì„±ì
        try:
            author_elem = driver.find_element(
                By.CSS_SELECTOR,
                "a.text-gray-400.hover\\:underline"
            )
            author_text = author_elem.text.strip()
            author = re.sub(r"^\s*by[:\s]+", "", author_text, flags=re.IGNORECASE).strip()
        except:
            author = "Creative Tim"

        # ì½”ë“œ ì¶”ì¶œ
        WebDriverWait(driver, 10).until(
            EC.element_to_be_clickable((By.XPATH, "//button[contains(., 'Show Code')]"))
        ).click()
        WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, ".view-lines.monaco-mouse-cursor-text"))
        )
        full_code = driver.execute_script("return monaco.editor.getModels()[0].getValue();")
        driver.quit()

        if not full_code or len(full_code.strip()) == 0:
            msg = f"âš ï¸ ì½”ë“œ ì—†ìŒ: {link}"
            log_output(msg)
            return msg

        # DB ì €ì¥
        with lock:
            cur.execute("""
                INSERT INTO components_tbl_test (
                    components_name,
                    components_description,
                    components_preview_html,
                    components_code,
                    components_library,
                    components_source_url,
                    components_author,
                    components_category
                )
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
            """, (name, description, None, full_code, "Tailwind", link, author, category))
            conn.commit()

        elapsed = round(time.time() - start, 1)
        msg = f"âœ… [{category}] ì €ì¥ ì™„ë£Œ: {name} (ì‘ì„±ì: {author}) â± {elapsed}s"
        log_output(msg)
        return msg

    except Exception as e:
        log_error(f"{link} - {e}")
        try: driver.quit()
        except: pass
        return f"âŒ ì˜¤ë¥˜: {link} ({e})"

# --- ì¹´í…Œê³ ë¦¬ ë‹¨ìœ„ í¬ë¡¤ë§ ---
def crawl_category(category_name, category_url, category_index, total_categories, total_saved_global):
    start_time = time.time()
    page = 1
    total_saved_local = 0

    print(f"\nğŸŒˆ [{category_index}/{total_categories}] {category_name} ì¹´í…Œê³ ë¦¬ ì‹œì‘!")

    while True:
        url = f"{category_url}?page={page}"
        print(f"\nğŸ“„ [{category_name}] í˜ì´ì§€ {page} í¬ë¡¤ë§ ì¤‘...")

        links = crawl_page(url)
        if not links:
            print(f"âš ï¸ [{category_name}] í˜ì´ì§€ {page} í•­ëª© ì—†ìŒ â†’ ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ë¡œ ì´ë™")
            break

        page_start = time.time()
        with concurrent.futures.ThreadPoolExecutor(max_workers=6) as executor:
            futures = [executor.submit(crawl_detail, link, category_name) for link in links]
            for future in concurrent.futures.as_completed(futures):
                msg = future.result()
                print(f"   {msg}")
                if msg.startswith("âœ…"):
                    total_saved_local += 1
                    total_saved_global[0] += 1  # ë¦¬ìŠ¤íŠ¸ ì°¸ì¡°ë¡œ ì „ì—­ ì¹´ìš´íŠ¸ ì¦ê°€

        # ETA ê³„ì‚°
        elapsed = time.time() - start_time
        progress = category_index / total_categories * 100
        avg_time = elapsed / max(category_index, 1)
        remaining = avg_time * (total_categories - category_index)
        eta_min = math.floor(remaining / 60)
        eta_sec = math.floor(remaining % 60)

        print(f"\nğŸ“Š ì¹´í…Œê³ ë¦¬ ì§„í–‰ë¥ : {progress:.2f}% | â± ETA: {eta_min:02d}:{eta_sec:02d} ë‚¨ìŒ")
        print(f"ğŸ“¦ [{category_name}] ëˆ„ì  {total_saved_local}ê°œ / ì „ì²´ {total_saved_global[0]}ê°œ ì €ì¥ ì™„ë£Œ")

        page += 1
        time.sleep(1)

    print(f"âœ… [{category_name}] ì™„ë£Œ - ì´ {total_saved_local}ê°œ ì €ì¥ë¨\n")


# --- ë©”ì¸ ì‹¤í–‰ ---
if __name__ == "__main__":
    categories = get_categories()
    total_saved_global = [0]  # ë¦¬ìŠ¤íŠ¸ë¡œ ê°ì‹¸ë©´ ì°¸ì¡° ê°€ëŠ¥ (thread-safe)

    print(f"\nğŸ“š ì´ {len(categories)}ê°œ ì¹´í…Œê³ ë¦¬ ë°œê²¬!\n")

    for i, (category_name, category_url) in enumerate(categories, start=1):
        crawl_category(category_name, category_url, i, len(categories), total_saved_global)

    cur.close()
    conn.close()
    print(f"\nğŸ‰ ì „ì²´ í¬ë¡¤ë§ ì™„ë£Œ! ì´ {total_saved_global[0]}ê°œ ì €ì¥ë¨ ğŸš€")
