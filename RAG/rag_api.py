from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse, HTMLResponse
from pydantic import BaseModel
from sentence_transformers import SentenceTransformer
from openai import OpenAI
import psycopg2
import os, json, requests

# ======== âš™ï¸ ê¸°ë³¸ ì„¤ì • ========
app = FastAPI()

# ì„ë² ë”© ëª¨ë¸ (ì§ˆì˜ â†’ ë²¡í„° ë³€í™˜ìš©)
model = SentenceTransformer("jhgan/ko-sroberta-multitask")
chat_sessions = {}

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

DB_CONFIG = {
    "dbname": os.getenv("DB_NAME"),
    "user": os.getenv("DB_USER"),
    "password": os.getenv("DB_PASSWORD"),
    "host": os.getenv("DB_HOST"),
    "port": int(os.getenv("DB_PORT", "5432")),
}


# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ======== ğŸ’¬ ìš”ì²­ ìŠ¤í‚¤ë§ˆ ========
class ChatRequest(BaseModel):
    query: str
    session_id: str = "default"

# ======== ğŸ” DB ê²€ìƒ‰ (RAG) ========
def retrieve_similar(query, top_k=3):
    emb = model.encode(query).tolist()
    with psycopg2.connect(**DB_CONFIG) as conn:
        with conn.cursor() as cur:
            cur.execute("""
                SELECT name, html, css, full_code, author, source_type,
                       1 - (embedding <=> %s::vector) AS similarity
                FROM unified_components_v3
                WHERE embedding IS NOT NULL
                ORDER BY embedding <=> %s::vector
                LIMIT %s;
            """, (emb, emb, top_k))
            rows = cur.fetchall()
    return rows


# ======== ğŸ§  í”„ë¡¬í”„íŠ¸ ìƒì„± (í•œêµ­ì–´ ë²„ì „) ========
def build_prompt_with_history(history, query):
    examples = retrieve_similar(query, top_k=3)
    examples_text = "\n\n".join([
        f"[{ex[5]}] ì˜ˆì‹œ (by {ex[4]}):\nHTML:\n{ex[1]}\n\nCSS:\n{ex[2]}"
        for ex in examples if ex[1] and ex[2]
    ])

    # ğŸ’¡ [ìˆ˜ì •] ì´ì „ ëŒ€í™” í…ìŠ¤íŠ¸ ê´€ë ¨ ë¬¸êµ¬ë¥¼ ì œê±°í•˜ê³  í˜„ì¬ í„´ì˜ ì§€ì‹œì‚¬í•­ë§Œ ë‚¨ê¹ë‹ˆë‹¤.
    prompt = f"""
        ë‹¹ì‹ ì€ ì„¸ê³„ì ì¸ ì›¹ ì•„í‹°ìŠ¤íŠ¸ì´ì CSS ë””ìì´ë„ˆì…ë‹ˆë‹¤.
        ì´ì „ ëŒ€í™” ê¸°ë¡(ë³„ë„ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ë¡œ ì „ë‹¬ë¨)ì„ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ìì˜ ì˜ë„ë¥¼ ì •í™•íˆ íŒŒì•…í•˜ê³ ,
        ì•„ë˜ ì£¼ì œì™€ ì°¸ê³  ì˜ˆì‹œì— ë§ëŠ” ê°ì„±ì ì´ê³  ì˜ˆìˆ ì ì¸ HTML/CSS í˜ì´ì§€ë¥¼ ì‘ì„±í•˜ì„¸ìš”.

        ì£¼ì œ: "{query}"

        ì°¸ê³  ì˜ˆì‹œ (ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê²€ìƒ‰ë¨):
        {examples_text}

        ê·œì¹™:
        1. ì™„ì „í•œ HTML5 ë¬¸ì„œ êµ¬ì¡°ë¡œ ì‘ì„±í•˜ì„¸ìš” (<!DOCTYPE html>ë¶€í„° </html>ê¹Œì§€ í¬í•¨).
        2. ì˜¤ì§ HTMLê³¼ ë‚´ë¶€ <style>ë§Œ ì‚¬ìš©í•˜ì„¸ìš”. (JS, í”„ë ˆì„ì›Œí¬, ì™¸ë¶€ ë¦¬ì†ŒìŠ¤ ì‚¬ìš© ê¸ˆì§€)
        3. ìƒ‰ê°ì€ ì¡°í™”ë¡­ê³ , ë””ìì¸ì€ ë¶€ë“œëŸ½ê³  ì„¸ë ¨ë˜ê²Œ í‘œí˜„í•˜ì„¸ìš”.
        4. ì—¬ë°±, ë¹„ìœ¨, íƒ€ì´í¬ê·¸ë˜í”¼ì˜ ê· í˜•ì„ ìœ ì§€í•˜ë©° ë¯¸ì  ì™„ì„±ë„ë¥¼ ë†’ì´ì„¸ìš”.
        5. ì§€ë‚˜ì¹˜ê²Œ ë‹¨ìˆœí•˜ê±°ë‚˜ ì¼ë°˜ì ì¸ ìŠ¤íƒ€ì¼ì„ í”¼í•˜ê³ , ì•„ë¦„ë‹¤ìš´ ì°½ì˜ì„±ì„ ë³´ì—¬ì£¼ì„¸ìš”.
        6. ì• ë‹ˆë©”ì´ì…˜ê³¼ ì›€ì§ì´ëŠ” ëª¨ì…˜ì„ ì¶”ê°€í•´ í™”ë ¤í•¨ì„ ì¶”êµ¬í•˜ì„¸í•´ìš”.
        7. ì½”ë“œ ìƒì„± í›„ ì‚¬ìš©ìì—ê²Œ ì¹œêµ¬ì²˜ëŸ¼ ëŒ€í•˜ë©° ê°„ëµí•œ ì½”ë“œ ì„¤ëª…ì„ í•´ì£¼ì„¸ìš”.
        8. ì‚¬ìš©ìê°€ ì…ë ¥í•œ í…ìŠ¤íŠ¸ë¡œ ì œëª©ì„ ë§Œë“¤ì§€ ë§ˆì„¸ìš”.
    """
    return prompt.strip()


# ======== ğŸš€ GPT-4o mini ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ========
@app.post("/chat/stream")
def chat_stream(req: ChatRequest):
    session_id = req.session_id
    query = req.query

    # ì„¸ì…˜ ë¶ˆëŸ¬ì˜¤ê¸° ë˜ëŠ” ì´ˆê¸°í™”
    if session_id not in chat_sessions:
        chat_sessions[session_id] = []

    history = chat_sessions[session_id]
    prompt = build_prompt_with_history(history, query)

    def stream_generator():
        with requests.post(
            "https://api.openai.com/v1/chat/completions",
            headers={
                "Authorization": "OPENAI_API_KEY",
                "Content-Type": "application/json"
            },
            json={
                "model": "gpt-4o-mini",
                "messages": [
                    {"role": "system", "content": "You are a creative web designer."},
                    {"role": "user", "content": prompt}
                ],
                "stream": True
            },
            stream=True
        ) as r:
            full_response = ""
            for line in r.iter_lines():
                if not line or not line.decode().startswith("data: "):
                    continue
                data = line.decode()[6:]
                if data.strip() == "[DONE]":
                    break
                try:
                    json_data = json.loads(data)
                    delta = json_data["choices"][0]["delta"]
                    if "content" in delta:
                        chunk = delta["content"]
                        full_response += chunk
                        yield chunk
                except Exception:
                    continue

            # ì„¸ì…˜ì— ì €ì¥
            history.append({"role": "user", "content": query})
            history.append({"role": "assistant", "content": full_response})

    return StreamingResponse(stream_generator(), media_type="text/event-stream")